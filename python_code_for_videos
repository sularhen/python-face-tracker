import cv2
import numpy as np
import os

# Crear carpeta para guardar los rostros, si no existe | creating a folder for saving faces
if not os.path.exists('Rostros encontrados'):
    print('Carpeta creada: Rostros encontrados')
    os.makedirs('Rostros encontrados')

# Ruta del archivo de video | path from video file
video_path = "yourvideo"  # Cambia el nombre y ruta de tu video aquí
cap = cv2.VideoCapture(video_path)

# Ruta del modelo ArcFace (archivo .onnx) | path from the ArcFace model
onnx_model_path = "arcfaceresnet100-8.onnx"  # El archivo ONNX que descargaste

# Verifica si el archivo del modelo existe | verifying if  file of the model exist
if not os.path.exists(onnx_model_path):
    raise FileNotFoundError("No se encuentra el archivo del modelo ONNX.")

# Cargar el modelo ArcFace | loading ArcFace model
net = cv2.dnn.readNetFromONNX(onnx_model_path)

# Ruta correcta para las cascadas Haar de OpenCV | add your path from haarcascade of OpenCV
haarcascade_frontface_path = r"C:your\route_from_haarcascade"
haarcascade_profileface_path = r"C:your\route_from_haarcascade"

# Verifica si los archivos Haar Cascade existen| Verifyng if Haar cascade files exist
if not os.path.exists(haarcascade_frontface_path):
    raise FileNotFoundError(f"El archivo Haar Cascade frontal no se encuentra en: {haarcascade_frontface_path}")
if not os.path.exists(haarcascade_profileface_path):
    raise FileNotFoundError(f"El archivo Haar Cascade de perfil no se encuentra en: {haarcascade_profileface_path}")

# Cargar los clasificadores Haar para detectar rostros| loading haar cascade clasifiers
face_cascade_front = cv2.CascadeClassifier(haarcascade_frontface_path)
face_cascade_profile = cv2.CascadeClassifier(haarcascade_profileface_path)

# Inicializar lista para almacenar los embeddings | starting the list for embeddings
embeddings = []
face_count = 0

while True:
    ret, frame = cap.read()
    if not ret:
        print("Fin del video o no se pudo leer.")
        break

    # Mantener la resolución original del video| keep the same resolution from the video
    height, width = frame.shape[:2]

    # Convertir la imagen a escala de grises para la detección de rostros| Change the color scale
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    # Detectar rostros frontales | Detect frontal faces
    faces_front = face_cascade_front.detectMultiScale(gray, 1.1, 4)
    # Detectar rostros de perfil| Detect lateral faces
    faces_profile = face_cascade_profile.detectMultiScale(gray, 1.1, 4)

    # Convertir las detecciones de cada tipo a una lista (debe ser lista de tuplas) | make list of both
    faces_front = [tuple(face) for face in faces_front]
    faces_profile = [tuple(face) for face in faces_profile]

    # Unificar las detecciones de rostros frontales y de perfil | make the list of both one list
    faces = faces_front + faces_profile  # Concatenar ambas listas

    # Para cada rostro detectado, obtener el embedding usando ArcFace
    for (x, y, w, h) in faces:
        face = frame[y:y+h, x:x+w]
        
        # Preprocesar la imagen del rostro para el modelo ArcFace
        blob = cv2.dnn.blobFromImage(face, 1.0, (112, 112), (127.5, 127.5, 127.5), swapRB=True, crop=True)
        net.setInput(blob)
        detections = net.forward()

        # Imprimir las dimensiones de las detecciones para verificar la estructura
        print(f"Dimensiones de detections: {detections.shape}")

        # Extraer el embedding del rostro
        embedding = detections.flatten()  # Convertir el vector 2D en 1D
        embeddings.append(embedding)

        # Mostrar el cuadro alrededor del rostro
        cv2.rectangle(frame, (x, y), (x + w, y + h), (128, 0, 255), 2)

        # Recortar el rostro detectado y guardarlo
        cropped_face = frame[y:y+h, x:x+w]
        cv2.imwrite(f'Rostros encontrados/rostro_{face_count}_cropped.jpg', cropped_face)
        
        # Crear la versión con zoom del rostro (ampliado)
        zoomed_face = cv2.resize(cropped_face, (200, 200), interpolation=cv2.INTER_CUBIC)
        cv2.imwrite(f'Rostros encontrados/rostro_{face_count}_zoomed.jpg', zoomed_face)

        face_count += 1

    # Mostrar el video con los rostros detectados
    cv2.imshow('Video', frame)

    # Guardar el rostro detectado si se presiona 's'
    k = cv2.waitKey(1)
    if k == ord('s'):  # Tecla 's' para almacenar el rostro
        cv2.imwrite(f'Rostros encontrados/rostro_{face_count}_saved.jpg', frame)
        print(f'Rostro {face_count} almacenado.')

    if k == 27:  # Tecla 'Esc' para salir
        break

# Liberar recursos
cap.release()
cv2.destroyAllWindows()
